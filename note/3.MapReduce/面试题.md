### 1.hive中如何快速的复制一张分区表(包括数据)
    (1) create table t1 like t2;
        开启动态分区,将t2表中的数据写入t1
    (2) create table t1 like t2
        使用hadoop fs -cp 命令将t2表的数据复制到t1中的数据路径中
        使用MSCK REPAIR TABLE new_table;修复新表的分区元数据

### 2.请简述mapreduce中，combiner，partition,sort作用？ 以及三者起作用的地方
    Combiner只应该适用于那种Reduce的输入（key：value与输出（key：value）类型完全一致，且不影响最终结果的场景。比如累加，最大值等，也可以用于过滤数据，在 map端将无效的数据过滤掉。

    在这些需求场景下，输出的数据是可以根据key值来作合并的，合并的目的是减少输出的数据量，减少IO的读写，减少网络传输,以提高MR的作业效率。

    1.combiner的作用就是在map端对输出先做一次合并,以减少传输到reducer的数据量.
    2.combiner最基本是实现本地key的归并,具有类似本地reduce,那么所有的结果都是reduce完成,效率会相对降低。
    3.使用combiner,先完成的map会在本地聚合,提升速度.
    4. combiner作用于环形缓冲区,在溢写(spill)磁盘之前会先进行合并,从而减少溢写的数据量

    partition意思为分开，分区。它分割map每个节点的结果，按照key分别映射给不同的reduce，也是可以自定义的。其实可以理解归类。也可以理解为根据key或value及reduce的数量来决定当前的这对输出数据最终应该交由哪个reduce task处理
    1. partition的作用就是把这些数据归类。每个map任务会针对输出进行分区，及对每一个reduce任务建立一个分区。划分分区由用户定义的partition函数控制，默认使用哈希函数来划分分区。 HashPartitioner是mapreduce的默认partitioner
    2. partitioner作用在写入环形缓冲区之前
    
    sort是环形缓冲区在spill之前,根据key的字典顺序进行排序
    1. sort 作用范围是环形缓冲区

### 3.mapreduce中的小文件过多,应该如何处理:
    小文件通常是指单个文件大小小于blockSize的文件,这种情况无法通过调整maxsize/minsize的方式使得map数减少,而是应该通过合并小文件的方式将小文件合并成inputsize大小的文件作为输入

### 4.HDFS的读写机制

### 5.map函数和reduce函数分别在什么地方被调用
 1. Mapper类中存在四个方法setup/map/run/cleanup
    1. setup 为map所需的环境做准备,如作业的配置信息  只被调用一次
    2. cleanup 在map执行完之后做清理的工作,如释放资源  只被调用一次
    3. map方法处理数据
    4. run方法调用setup/cleanup这两个方法只调用一次,之后会循环调用map方法
    5. run方法的输入就是对应inputsplit切片,一个inputsplit切片会启用一个maptask,map方法的输入就是inputsplit中的一行文本,所以需要调用多次
 2. Reducer类中存在的四个方法
    1. setup 为reduce所需的环境做准备,如作业的配置信息  只被调用一次
    2. cleanup 在reduce执行完之后做清理的工作,如释放资源  只被调用一次
    3. reduce方法处理数据
    4. run方法调用setup/cleanup这两个方法只调用一次,之后会循环调用reduce方法
    5. run方法对应的输入是map方法产生的结果数据(归并之后的结果)<key, (list of values)> ;reduce方法的输入就是<key, (list of values)>,因此需要遍历<key, (list of values),将values取出进行逻辑计算