### 1.hive中如何快速的复制一张分区表(包括数据)
    (1) create table t1 like t2;
        开启动态分区,将t2表中的数据写入t1
    (2) create table t1 like t2
        使用hadoop fs -cp 命令将t2表的数据复制到t1中的数据路径中
        使用MSCK REPAIR TABLE new_table;修复新表的分区元数据

### 2.请简述mapreduce中，combiner，partition,sort作用？ 以及三者起作用的地方
    Combiner只应该适用于那种Reduce的输入（key：value与输出（key：value）类型完全一致，且不影响最终结果的场景。比如累加，最大值等，也可以用于过滤数据，在 map端将无效的数据过滤掉。

    在这些需求场景下，输出的数据是可以根据key值来作合并的，合并的目的是减少输出的数据量，减少IO的读写，减少网络传输,以提高MR的作业效率。

    1.combiner的作用就是在map端对输出先做一次合并,以减少传输到reducer的数据量.
    2.combiner最基本是实现本地key的归并,具有类似本地reduce,那么所有的结果都是reduce完成,效率会相对降低。
    3.使用combiner,先完成的map会在本地聚合,提升速度.
    4. combiner作用于环形缓冲区,在溢写(spill)磁盘之前会先进行合并,从而减少溢写的数据量

    partition意思为分开，分区。它分割map每个节点的结果，按照key分别映射给不同的reduce，也是可以自定义的。其实可以理解归类。也可以理解为根据key或value及reduce的数量来决定当前的这对输出数据最终应该交由哪个reduce task处理
    1. partition的作用就是把这些数据归类。每个map任务会针对输出进行分区，及对每一个reduce任务建立一个分区。划分分区由用户定义的partition函数控制，默认使用哈希函数来划分分区。 HashPartitioner是mapreduce的默认partitioner
    2. partitioner作用在写入环形缓冲区之前
    
    sort是环形缓冲区在spill之前,根据key的字典顺序进行排序
    1. sort 作用范围是环形缓冲区

### 3.mapreduce中的小文件过多,应该如何处理:
    小文件通常是指单个文件大小小于blockSize的文件,这种情况无法通过调整maxsize/minsize的方式使得map数减少,而是应该通过合并小文件的方式将小文件合并成inputsize大小的文件作为输入

### 4.HDFS的读写机制
1. HDFS是一个分布式文件系统,datanode负责存储文件的数据块(一个block默认可以存储为3份);namenode负责管理元数据,维护整个文件系统的文件目录,文件的元信息和每个文件对应的数据块列表,以及接受用户请求
2. HDFS优点:(1) 高容错(多份存储) (2) 适合大数据处理 (3) 流式访问,允许一次存储多次读取,不允许修改,保证数据一致性   
       缺点:(1) 不适合做低延迟的数据查询 (2) 对大量小文件处理较慢,会增加namenode存储空间 (3) 数据只能追加不能修改
3. 写流程
   (1) 客户端向namenode请求上传文件,namenode会对文件进行检查(是否存在、是否有权限)
   (2) namenode返回是否可以上传数据
   (3) 客户端请求上传数据的datanode(默认三个)
   (4) namenode返回三个可以上传数据的datanode 
   (5) 客户端请求想datanode1上传数据,并且建立管道 dn1调用dn2, dn2调用dn3
   (6) 客户端开始向dn1上传数据(第一个block),dn1读取到的数据会放在本地的缓存中(packet 64k为单位),接着dn1会传给dn2,dn2传给dn3
4. 读流程
   (1) 客户端向namenode请求下载数据,namenode通过查找元数据,验证权限,找到文件块所在的地址,返回给客户端
   (2) 客户端会根据namenode返回的datanode中选一个请求下载数据
   (3) datanode开始传输数据给客户端,packet为单位,数据会先在本地缓存中在写入目标文件

### 5.map函数和reduce函数分别在什么地方被调用
 1. Mapper类中存在四个方法setup/map/run/cleanup
    1. setup 为map所需的环境做准备,如作业的配置信息  只被调用一次
    2. cleanup 在map执行完之后做清理的工作,如释放资源  只被调用一次
    3. map方法处理数据
    4. run方法调用setup/cleanup这两个方法只调用一次,之后会循环调用map方法
    5. run方法的输入就是对应inputsplit切片,一个inputsplit切片会启用一个maptask,map方法的输入就是inputsplit中的一行文本,所以需要调用多次
 2. Reducer类中存在的四个方法
    1. setup 为reduce所需的环境做准备,如作业的配置信息  只被调用一次
    2. cleanup 在reduce执行完之后做清理的工作,如释放资源  只被调用一次
    3. reduce方法处理数据
    4. run方法调用setup/cleanup这两个方法只调用一次,之后会循环调用reduce方法
    5. run方法对应的输入是map方法产生的结果数据(归并之后的结果)<key, (list of values)> ;reduce方法的输入就是<key, (list of values)>,因此需要遍历<key, (list of values),将values取出进行逻辑计算

### 6. 分区跟分桶的区别
 1. 分区:     
    (1)分区是指按照数据表的某列或者多列分为多个区,形式上可以理解为分了文件夹,分区字段不是数据表中真实存在的一个列,而是伪列
    (2)分区可分为单值分区/范围分区
    (3)通过表分区,能够更方便进行数据管理,在做数据查询时能够在特定的数据区域进行查找,避免全表扫描,提高数据查询效率
 2. 分桶:   
    (1) 分桶是相对分区更细粒度的划分,分桶是将数据按照表中某一列(真实列)的hash值进行区分,存放于不同的文件中(桶) clustered by (id) into 5 bukets
    (2) 如果分桶键和排序键不同，且按降序排列，使用Distribute by … Sort by分桶排序
    (3) 如果分桶键和排序键相同，且按升序排列（默认），使用 Cluster by 分桶排序
    (4) 获得更高的查询处理效率。桶为表加上了额外的结构，Hive 在处理有些查询时能利用这个结构 ,join操作能直接使用分桶的列进行关联即可
    (5) 使取样（sampling）更高效。在处理大规模数据集时，在开发和修改查询的阶段，如果能在数据集的一小部分数据上试运行查询，会带来很多方便

### 7. row_number/rank/dense_rank
   (1) row_number不管排名如何,会按照顺序进行排序,不会并列也不会条约
   (2) rank 排名相同则并列,后续会有跳跃 1 2 2 4 
   (3) dense_rank 排名相同则并列,后续不会跳跃  1 2 2 3 

### 8. map端的数据倾斜和reduce端数据倾斜
1. map端倾斜:    
    (1) 原因: (1)由于输入文件的大小特别不均匀,并且存在很多小文件,导致当前表在进行数据读取时负载不均衡. (2) 在map端做聚合时(如combiner),某些key特别多从而导致倾斜   
    (2) 解决方案: (1) 合并小文件,设置每个map处理数据最大文件的大小 (2) distribute by rand(),来打乱数据分布,使数据尽可能分布均匀
2. join倾斜:    
    (1) 原因: (1) join的表数据量都很大,且存在key空值较多 (2) join的表都很大,且是由于热点数据过多导致  
    (2) 解决方案: (1) 将空值打散成随机值避免聚集,并且加上特殊标识,便于后续识别 (2) 将热点数据与非热点数据区分关联
3. reduce端倾斜:   
    (1) 原因: 主要是由于key的分布不均导致reduce在获取map端输出时某个key数据量过大;   
    (2) 解决方案 参考join倾斜

### 9. 数据仓库的模型
1. 范式建模
2. 维度建模
3. data vault建模

### 10. 常用表设计